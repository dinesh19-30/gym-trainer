{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8c49591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a video file for squat analysis...\n",
      "Selected file: C:/Users/acer/Downloads/output_sample.mp4\n",
      "Processing video... Press 'q' to quit preview.\n",
      "✅ Done!\n",
      "Correct Squats: 0\n",
      "Improper Squats: 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "def find_angle(p1, p2, ref_pt):\n",
    "    p1_ref = np.array(p1) - np.array(ref_pt)\n",
    "    p2_ref = np.array(p2) - np.array(ref_pt)\n",
    "    cos_theta = np.dot(p1_ref, p2_ref) / (np.linalg.norm(p1_ref) * np.linalg.norm(p2_ref) + 1e-6)\n",
    "    theta = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n",
    "    return int(np.degrees(theta))\n",
    "\n",
    "def get_landmark_array(pose_landmark, key, frame_width, frame_height):\n",
    "    return np.array([\n",
    "        int(pose_landmark[key].x * frame_width),\n",
    "        int(pose_landmark[key].y * frame_height)\n",
    "    ])\n",
    "\n",
    "def get_mediapipe_pose(static_image_mode=False, model_complexity=1, smooth_landmarks=True,\n",
    "                       min_detection_confidence=0.5, min_tracking_confidence=0.5):\n",
    "    return mp.solutions.pose.Pose(\n",
    "        static_image_mode=static_image_mode,\n",
    "        model_complexity=model_complexity,\n",
    "        smooth_landmarks=smooth_landmarks,\n",
    "        min_detection_confidence=min_detection_confidence,\n",
    "        min_tracking_confidence=min_tracking_confidence\n",
    "    )\n",
    "\n",
    "def draw_text(img, msg, pos, font_scale=0.8, text_color=(255, 255, 255),\n",
    "              text_color_bg=(0, 0, 0), box_offset=(20, 10)):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_thickness = 2\n",
    "    x, y = pos\n",
    "    text_size, _ = cv2.getTextSize(msg, font, font_scale, font_thickness)\n",
    "    text_w, text_h = text_size\n",
    "    rec_start = tuple(p - o for p, o in zip(pos, box_offset))\n",
    "    rec_end = tuple(m + n - o for m, n, o in zip((x + text_w, y + text_h), box_offset, (25, 0)))\n",
    "    cv2.rectangle(img, rec_start, rec_end, text_color_bg, -1)\n",
    "    cv2.putText(img, msg, (int(rec_start[0] + 6), int(y + text_h + font_scale - 1)), font,\n",
    "                font_scale, text_color, font_thickness, cv2.LINE_AA)\n",
    "    return text_size\n",
    "\n",
    "def draw_dotted_line(frame, pt1, pt2, color, thickness=2, gap=10):\n",
    "    dist = int(math.hypot(pt2[0] - pt1[0], pt2[1] - pt1[1]))\n",
    "    for i in range(0, dist, gap * 2):\n",
    "        start = (int(pt1[0] + (pt2[0] - pt1[0]) * i / dist),\n",
    "                 int(pt1[1] + (pt2[1] - pt1[1]) * i / dist))\n",
    "        end = (int(pt1[0] + (pt2[0] - pt1[0]) * (i + gap) / dist),\n",
    "               int(pt1[1] + (pt2[1] - pt1[1]) * (i + gap) / dist))\n",
    "        if end[0] > frame.shape[1] or end[1] > frame.shape[0]:\n",
    "            break\n",
    "        cv2.line(frame, start, end, color, thickness)\n",
    "\n",
    "def get_thresholds_beginner():\n",
    "    return {\n",
    "        'HIP_KNEE_VERT': {'NORMAL': (0, 32), 'TRANS': (35, 65), 'PASS': (70, 95)},\n",
    "        'HIP_THRESH': [10, 50],\n",
    "        'ANKLE_THRESH': 45,\n",
    "        'KNEE_THRESH': [50, 70, 95],\n",
    "        'OFFSET_THRESH': 35.0,\n",
    "        'INACTIVE_THRESH': 15.0,\n",
    "        'CNT_FRAME_THRESH': 50\n",
    "    }\n",
    "\n",
    "def get_thresholds_pro():\n",
    "    return {\n",
    "        'HIP_KNEE_VERT': {'NORMAL': (0, 32), 'TRANS': (35, 65), 'PASS': (80, 95)},\n",
    "        'HIP_THRESH': [15, 50],\n",
    "        'ANKLE_THRESH': 30,\n",
    "        'KNEE_THRESH': [50, 80, 95],\n",
    "        'OFFSET_THRESH': 35.0,\n",
    "        'INACTIVE_THRESH': 15.0,\n",
    "        'CNT_FRAME_THRESH': 50\n",
    "    }\n",
    "\n",
    "class ProcessFrame:\n",
    "    def __init__(self, thresholds, flip_frame=False):\n",
    "        self.flip_frame = flip_frame\n",
    "        self.thresholds = thresholds\n",
    "        self.COLORS = {\n",
    "            'blue': (0, 127, 255), 'red': (255, 50, 50), 'green': (0, 255, 127),\n",
    "            'light_green': (100, 233, 127), 'yellow': (255, 255, 0),\n",
    "            'magenta': (255, 0, 255), 'white': (255, 255, 255),\n",
    "            'cyan': (0, 255, 255), 'light_blue': (102, 204, 255)\n",
    "        }\n",
    "        self.dict_features = {\n",
    "            'left': {'shoulder': 11, 'elbow': 13, 'wrist': 15,\n",
    "                     'hip': 23, 'knee': 25, 'ankle': 27, 'foot': 31},\n",
    "            'right': {'shoulder': 12, 'elbow': 14, 'wrist': 16,\n",
    "                      'hip': 24, 'knee': 26, 'ankle': 28, 'foot': 32},\n",
    "            'nose': 0\n",
    "        }\n",
    "        self.state_tracker = {\n",
    "            'state_seq': [], 'start_inactive_time': time.perf_counter(),\n",
    "            'start_inactive_time_front': time.perf_counter(), 'INACTIVE_TIME': 0.0,\n",
    "            'INACTIVE_TIME_FRONT': 0.0, 'DISPLAY_TEXT': np.full((4,), False),\n",
    "            'COUNT_FRAMES': np.zeros((4,), dtype=np.int64), 'LOWER_HIPS': False,\n",
    "            'INCORRECT_POSTURE': False, 'prev_state': None, 'curr_state': None,\n",
    "            'SQUAT_COUNT': 0, 'IMPROPER_SQUAT': 0\n",
    "        }\n",
    "\n",
    "    def _get_landmark_features(self, landmarks, side, frame_width, frame_height):\n",
    "        features = self.dict_features[side]\n",
    "        coords = {}\n",
    "        for key, lm_id in features.items():\n",
    "            lm = landmarks[lm_id]\n",
    "            coords[key] = (int(lm.x * frame_width), int(lm.y * frame_height))\n",
    "        return coords\n",
    "\n",
    "    def _determine_side(self, landmarks, frame_width):\n",
    "        left_hip = landmarks[self.dict_features['left']['hip']]\n",
    "        right_hip = landmarks[self.dict_features['right']['hip']]\n",
    "        return 'left' if left_hip.x < right_hip.x else 'right'\n",
    "\n",
    "    def process(self, frame: np.ndarray, pose):\n",
    "        frame_height, frame_width, _ = frame.shape\n",
    "        results = pose.process(frame)\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            side = self._determine_side(landmarks, frame_width)\n",
    "            coords = self._get_landmark_features(landmarks, side, frame_width, frame_height)\n",
    "            hip_knee_vert_angle = find_angle(coords['hip'], coords['knee'], (coords['knee'][0], 0))\n",
    "            knee_angle = find_angle(coords['hip'], coords['knee'], coords['ankle'])\n",
    "\n",
    "            if self.thresholds['HIP_KNEE_VERT']['NORMAL'][0] <= hip_knee_vert_angle <= self.thresholds['HIP_KNEE_VERT']['NORMAL'][1]:\n",
    "                self.state_tracker['curr_state'] = 's1'\n",
    "            elif self.thresholds['HIP_KNEE_VERT']['TRANS'][0] <= hip_knee_vert_angle <= self.thresholds['HIP_KNEE_VERT']['TRANS'][1]:\n",
    "                self.state_tracker['curr_state'] = 's2'\n",
    "            elif self.thresholds['HIP_KNEE_VERT']['PASS'][0] <= hip_knee_vert_angle <= self.thresholds['HIP_KNEE_VERT']['PASS'][1]:\n",
    "                self.state_tracker['curr_state'] = 's3'\n",
    "\n",
    "            if self.state_tracker['curr_state'] != self.state_tracker['prev_state']:\n",
    "                if self.state_tracker['curr_state'] == 's3':\n",
    "                    if not (self.thresholds['KNEE_THRESH'][1] < knee_angle < self.thresholds['KNEE_THRESH'][2]):\n",
    "                        self.state_tracker['IMPROPER_SQUAT'] += 1\n",
    "                        self.state_tracker['INCORRECT_POSTURE'] = True\n",
    "                    else:\n",
    "                        self.state_tracker['INCORRECT_POSTURE'] = False\n",
    "                if self.state_tracker['prev_state'] == 's3' and self.state_tracker['curr_state'] == 's2':\n",
    "                    if not self.state_tracker['INCORRECT_POSTURE']:\n",
    "                        self.state_tracker['SQUAT_COUNT'] += 1\n",
    "                self.state_tracker['prev_state'] = self.state_tracker['curr_state']\n",
    "\n",
    "            mp.solutions.drawing_utils.draw_landmarks(\n",
    "                frame, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(255,255,0), thickness=2, circle_radius=2),\n",
    "                connection_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(0,255,0), thickness=2)\n",
    "            )\n",
    "\n",
    "            draw_dotted_line(frame, coords['knee'], (coords['knee'][0], 0), self.COLORS['blue'])\n",
    "            cv2.putText(frame, f\"Knee Angle: {knee_angle}\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, self.COLORS['white'], 2)\n",
    "            cv2.putText(frame, f\"Hip-Knee-Vert Angle: {hip_knee_vert_angle}\", (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, self.COLORS['white'], 2)\n",
    "            draw_text(frame, f\"CORRECT SQUATS: {self.state_tracker['SQUAT_COUNT']}\",\n",
    "                      pos=(frame_width - 300, 30), text_color_bg=self.COLORS['green'])\n",
    "            draw_text(frame, f\"IMPROPER SQUATS: {self.state_tracker['IMPROPER_SQUAT']}\",\n",
    "                      pos=(frame_width - 300, 80), text_color_bg=self.COLORS['red'])\n",
    "        else:\n",
    "            cv2.putText(frame, \"No person detected\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, self.COLORS['red'], 2)\n",
    "        return frame\n",
    "\n",
    "# ========================= MAIN EXECUTION =========================\n",
    "MODE = 'Beginner'\n",
    "if MODE == 'Beginner':\n",
    "    thresholds = get_thresholds_beginner()\n",
    "else:\n",
    "    thresholds = get_thresholds_pro()\n",
    "\n",
    "# Open file picker dialog\n",
    "Tk().withdraw()\n",
    "print(\"Select a video file for squat analysis...\")\n",
    "video_path = askopenfilename(title=\"Select video file\", filetypes=[(\"Video files\", \"*.mp4;*.avi;*.mov\")])\n",
    "\n",
    "if not video_path:\n",
    "    print(\"No file selected. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Selected file: {video_path}\")\n",
    "pose = get_mediapipe_pose()\n",
    "process_frame = ProcessFrame(thresholds=thresholds)\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file {video_path}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Processing video... Press 'q' to quit preview.\")\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    processed_frame = process_frame.process(frame_rgb, pose)\n",
    "    frame_bgr = cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow(\"Squat Analysis\", frame_bgr)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"✅ Done!\\nCorrect Squats: {process_frame.state_tracker['SQUAT_COUNT']}\\nImproper Squats: {process_frame.state_tracker['IMPROPER_SQUAT']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
